{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "hspvkHBPFLOe",
        "outputId": "9a58658c-7990-4d0b-e811-a33010d93be1"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "CUDA is available!  Training on GPU ...\n"
          ]
        }
      ],
      "source": [
        "import torch\n",
        "import numpy as np\n",
        "\n",
        "# check if CUDA is available\n",
        "train_on_gpu = torch.cuda.is_available()\n",
        "\n",
        "if not train_on_gpu:\n",
        "    print('CUDA is not available.  Training on CPU ...')\n",
        "else:\n",
        "    print('CUDA is available!  Training on GPU ...')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "lx7e4ADDmq9a",
        "outputId": "9aa1f917-2c98-4104-df76-ab5bb105bcb4"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Downloading http://yann.lecun.com/exdb/mnist/train-images-idx3-ubyte.gz\n",
            "Downloading http://yann.lecun.com/exdb/mnist/train-images-idx3-ubyte.gz to data/MNIST/raw/train-images-idx3-ubyte.gz\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 9912422/9912422 [00:00<00:00, 70307982.16it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Extracting data/MNIST/raw/train-images-idx3-ubyte.gz to data/MNIST/raw\n",
            "\n",
            "Downloading http://yann.lecun.com/exdb/mnist/train-labels-idx1-ubyte.gz\n",
            "Downloading http://yann.lecun.com/exdb/mnist/train-labels-idx1-ubyte.gz to data/MNIST/raw/train-labels-idx1-ubyte.gz\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 28881/28881 [00:00<00:00, 68399601.26it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Extracting data/MNIST/raw/train-labels-idx1-ubyte.gz to data/MNIST/raw\n",
            "\n",
            "Downloading http://yann.lecun.com/exdb/mnist/t10k-images-idx3-ubyte.gz\n",
            "Downloading http://yann.lecun.com/exdb/mnist/t10k-images-idx3-ubyte.gz to data/MNIST/raw/t10k-images-idx3-ubyte.gz\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 1648877/1648877 [00:00<00:00, 33380270.76it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Extracting data/MNIST/raw/t10k-images-idx3-ubyte.gz to data/MNIST/raw\n",
            "\n",
            "Downloading http://yann.lecun.com/exdb/mnist/t10k-labels-idx1-ubyte.gz\n",
            "Downloading http://yann.lecun.com/exdb/mnist/t10k-labels-idx1-ubyte.gz to data/MNIST/raw/t10k-labels-idx1-ubyte.gz\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 4542/4542 [00:00<00:00, 20053188.18it/s]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Extracting data/MNIST/raw/t10k-labels-idx1-ubyte.gz to data/MNIST/raw\n",
            "\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\n"
          ]
        }
      ],
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.optim as optim\n",
        "import torch.nn.functional as F\n",
        "import torchvision.transforms as transforms\n",
        "from torchvision.datasets import MNIST\n",
        "from torch.utils.data import DataLoader, random_split\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "# Step 1: Load and Prepare the MNIST Dataset\n",
        "transform = transforms.Compose([transforms.ToTensor(),\n",
        "                                transforms.Normalize((0.5,), (0.5,))])\n",
        "\n",
        "# Load MNIST dataset\n",
        "full_train_data = MNIST(root='data', train=True, download=True, transform=transform)\n",
        "test_data = MNIST(root='data', train=False, download=True, transform=transform)\n",
        "\n",
        "# Split full training data into training and validation\n",
        "train_size = int(0.8 * len(full_train_data))\n",
        "valid_size = len(full_train_data) - train_size\n",
        "train_data, valid_data = random_split(full_train_data, [train_size, valid_size])\n",
        "\n",
        "# Create data loaders\n",
        "train_loader = DataLoader(train_data, batch_size=64, shuffle=True)\n",
        "valid_loader = DataLoader(valid_data, batch_size=64, shuffle=True)\n",
        "test_loader = DataLoader(test_data, batch_size=64, shuffle=False)\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "P_2xTMpPmq9b"
      },
      "outputs": [],
      "source": [
        "# Step 2: Define the Deep Neural Network Model\n",
        "class DeepNN(nn.Module):\n",
        "    def __init__(self):\n",
        "        super(DeepNN, self).__init__()\n",
        "        self.fc1 = nn.Linear(28*28, 512)\n",
        "        # self.fc2 = nn.Linear(512, 256)\n",
        "        self.fc3 = nn.Linear(512, 128)\n",
        "        self.fc4 = nn.Linear(128, 64)\n",
        "        self.fc5 = nn.Linear(64, 10)\n",
        "        self.dropout = nn.Dropout(0.2)\n",
        "\n",
        "    def forward(self, x):\n",
        "        x = x.view(-1, 28*28)  # Flatten the images\n",
        "        x = self.dropout(F.relu(self.fc1(x)))\n",
        "        # x = self.dropout(F.relu(self.fc2(x)))\n",
        "        x = self.dropout(F.relu(self.fc3(x)))\n",
        "        x = self.dropout(F.relu(self.fc4(x)))\n",
        "        x = self.fc5(x)\n",
        "        return x\n",
        "\n",
        "# Initialize the network\n",
        "model = DeepNN()\n",
        "\n",
        "# Step 3: Define the Loss Function and Optimizer\n",
        "criterion = nn.CrossEntropyLoss()\n",
        "optimizer = optim.Adam(model.parameters(), lr=0.001)\n",
        "if train_on_gpu:\n",
        "  model.cuda()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ThnjORhZmq9c",
        "outputId": "af20780f-794e-490f-f66c-0d8e2ffa86c0"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 1/50 \t Training Loss: 0.4932 \t Validation Loss: 0.1925\n",
            "Epoch 2/50 \t Training Loss: 0.2341 \t Validation Loss: 0.1670\n",
            "Epoch 3/50 \t Training Loss: 0.1876 \t Validation Loss: 0.1301\n",
            "Epoch 4/50 \t Training Loss: 0.1612 \t Validation Loss: 0.1190\n",
            "Epoch 5/50 \t Training Loss: 0.1441 \t Validation Loss: 0.1133\n"
          ]
        },
        {
          "ename": "KeyboardInterrupt",
          "evalue": "",
          "output_type": "error",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
            "Cell \u001b[0;32mIn[9], line 71\u001b[0m\n\u001b[1;32m     69\u001b[0m \u001b[38;5;66;03m# Run the training and testing\u001b[39;00m\n\u001b[1;32m     70\u001b[0m num_epochs \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m50\u001b[39m\n\u001b[0;32m---> 71\u001b[0m valid_losses\u001b[38;5;241m=\u001b[39m\u001b[43mtrain_model\u001b[49m\u001b[43m(\u001b[49m\u001b[43mnum_epochs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     72\u001b[0m test_model()\n",
            "Cell \u001b[0;32mIn[9], line 8\u001b[0m, in \u001b[0;36mtrain_model\u001b[0;34m(num_epochs)\u001b[0m\n\u001b[1;32m      6\u001b[0m train_loss \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m0.0\u001b[39m\n\u001b[1;32m      7\u001b[0m model\u001b[38;5;241m.\u001b[39mtrain()\n\u001b[0;32m----> 8\u001b[0m \u001b[43m\u001b[49m\u001b[38;5;28;43;01mfor\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mimages\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mlabels\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01min\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mtrain_loader\u001b[49m\u001b[43m:\u001b[49m\n\u001b[1;32m      9\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;28;43;01mif\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mtrain_on_gpu\u001b[49m\u001b[43m:\u001b[49m\n\u001b[1;32m     10\u001b[0m \u001b[43m        \u001b[49m\u001b[43mimages\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mlabels\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m \u001b[49m\u001b[43mimages\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcuda\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mlabels\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcuda\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n",
            "File \u001b[0;32m~/.local/lib/python3.11/site-packages/torch/utils/data/dataloader.py:630\u001b[0m, in \u001b[0;36m_BaseDataLoaderIter.__next__\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    627\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_sampler_iter \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m    628\u001b[0m     \u001b[38;5;66;03m# TODO(https://github.com/pytorch/pytorch/issues/76750)\u001b[39;00m\n\u001b[1;32m    629\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_reset()  \u001b[38;5;66;03m# type: ignore[call-arg]\u001b[39;00m\n\u001b[0;32m--> 630\u001b[0m data \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_next_data\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    631\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_num_yielded \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[38;5;241m1\u001b[39m\n\u001b[1;32m    632\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_dataset_kind \u001b[38;5;241m==\u001b[39m _DatasetKind\u001b[38;5;241m.\u001b[39mIterable \u001b[38;5;129;01mand\u001b[39;00m \\\n\u001b[1;32m    633\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_IterableDataset_len_called \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;129;01mand\u001b[39;00m \\\n\u001b[1;32m    634\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_num_yielded \u001b[38;5;241m>\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_IterableDataset_len_called:\n",
            "File \u001b[0;32m~/.local/lib/python3.11/site-packages/torch/utils/data/dataloader.py:674\u001b[0m, in \u001b[0;36m_SingleProcessDataLoaderIter._next_data\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    672\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m_next_data\u001b[39m(\u001b[38;5;28mself\u001b[39m):\n\u001b[1;32m    673\u001b[0m     index \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_next_index()  \u001b[38;5;66;03m# may raise StopIteration\u001b[39;00m\n\u001b[0;32m--> 674\u001b[0m     data \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_dataset_fetcher\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfetch\u001b[49m\u001b[43m(\u001b[49m\u001b[43mindex\u001b[49m\u001b[43m)\u001b[49m  \u001b[38;5;66;03m# may raise StopIteration\u001b[39;00m\n\u001b[1;32m    675\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_pin_memory:\n\u001b[1;32m    676\u001b[0m         data \u001b[38;5;241m=\u001b[39m _utils\u001b[38;5;241m.\u001b[39mpin_memory\u001b[38;5;241m.\u001b[39mpin_memory(data, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_pin_memory_device)\n",
            "File \u001b[0;32m~/.local/lib/python3.11/site-packages/torch/utils/data/_utils/fetch.py:49\u001b[0m, in \u001b[0;36m_MapDatasetFetcher.fetch\u001b[0;34m(self, possibly_batched_index)\u001b[0m\n\u001b[1;32m     47\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mauto_collation:\n\u001b[1;32m     48\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mhasattr\u001b[39m(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdataset, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m__getitems__\u001b[39m\u001b[38;5;124m\"\u001b[39m) \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdataset\u001b[38;5;241m.\u001b[39m__getitems__:\n\u001b[0;32m---> 49\u001b[0m         data \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdataset\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m__getitems__\u001b[49m\u001b[43m(\u001b[49m\u001b[43mpossibly_batched_index\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     50\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m     51\u001b[0m         data \u001b[38;5;241m=\u001b[39m [\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdataset[idx] \u001b[38;5;28;01mfor\u001b[39;00m idx \u001b[38;5;129;01min\u001b[39;00m possibly_batched_index]\n",
            "File \u001b[0;32m~/.local/lib/python3.11/site-packages/torch/utils/data/dataset.py:364\u001b[0m, in \u001b[0;36mSubset.__getitems__\u001b[0;34m(self, indices)\u001b[0m\n\u001b[1;32m    362\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdataset\u001b[38;5;241m.\u001b[39m__getitems__([\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mindices[idx] \u001b[38;5;28;01mfor\u001b[39;00m idx \u001b[38;5;129;01min\u001b[39;00m indices])  \u001b[38;5;66;03m# type: ignore[attr-defined]\u001b[39;00m\n\u001b[1;32m    363\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m--> 364\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43m[\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdataset\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mindices\u001b[49m\u001b[43m[\u001b[49m\u001b[43midx\u001b[49m\u001b[43m]\u001b[49m\u001b[43m]\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mfor\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43midx\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01min\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mindices\u001b[49m\u001b[43m]\u001b[49m\n",
            "File \u001b[0;32m~/.local/lib/python3.11/site-packages/torch/utils/data/dataset.py:364\u001b[0m, in \u001b[0;36m<listcomp>\u001b[0;34m(.0)\u001b[0m\n\u001b[1;32m    362\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdataset\u001b[38;5;241m.\u001b[39m__getitems__([\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mindices[idx] \u001b[38;5;28;01mfor\u001b[39;00m idx \u001b[38;5;129;01min\u001b[39;00m indices])  \u001b[38;5;66;03m# type: ignore[attr-defined]\u001b[39;00m\n\u001b[1;32m    363\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m--> 364\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m [\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdataset\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mindices\u001b[49m\u001b[43m[\u001b[49m\u001b[43midx\u001b[49m\u001b[43m]\u001b[49m\u001b[43m]\u001b[49m \u001b[38;5;28;01mfor\u001b[39;00m idx \u001b[38;5;129;01min\u001b[39;00m indices]\n",
            "File \u001b[0;32m~/.local/lib/python3.11/site-packages/torchvision/datasets/mnist.py:138\u001b[0m, in \u001b[0;36mMNIST.__getitem__\u001b[0;34m(self, index)\u001b[0m\n\u001b[1;32m    130\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m__getitem__\u001b[39m(\u001b[38;5;28mself\u001b[39m, index: \u001b[38;5;28mint\u001b[39m) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m Tuple[Any, Any]:\n\u001b[1;32m    131\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[1;32m    132\u001b[0m \u001b[38;5;124;03m    Args:\u001b[39;00m\n\u001b[1;32m    133\u001b[0m \u001b[38;5;124;03m        index (int): Index\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    136\u001b[0m \u001b[38;5;124;03m        tuple: (image, target) where target is index of the target class.\u001b[39;00m\n\u001b[1;32m    137\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[0;32m--> 138\u001b[0m     img, target \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdata[index], \u001b[38;5;28;43mint\u001b[39;49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtargets\u001b[49m\u001b[43m[\u001b[49m\u001b[43mindex\u001b[49m\u001b[43m]\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    140\u001b[0m     \u001b[38;5;66;03m# doing this so that it is consistent with all other datasets\u001b[39;00m\n\u001b[1;32m    141\u001b[0m     \u001b[38;5;66;03m# to return a PIL Image\u001b[39;00m\n\u001b[1;32m    142\u001b[0m     img \u001b[38;5;241m=\u001b[39m Image\u001b[38;5;241m.\u001b[39mfromarray(img\u001b[38;5;241m.\u001b[39mnumpy(), mode\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mL\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
          ]
        }
      ],
      "source": [
        "# Step 4: Train the Model\n",
        "def train_model(num_epochs):\n",
        "    train_losses = []  # List to store training losses\n",
        "    valid_losses = []\n",
        "    for epoch in range(num_epochs):\n",
        "        train_loss = 0.0\n",
        "        model.train()\n",
        "        for images, labels in train_loader:\n",
        "            if train_on_gpu:\n",
        "                images, labels = images.cuda(), labels.cuda()\n",
        "            optimizer.zero_grad()\n",
        "            outputs = model(images)\n",
        "            loss = criterion(outputs, labels)\n",
        "            loss.backward()\n",
        "            optimizer.step()\n",
        "            train_loss += loss.item() * images.size(0)\n",
        "\n",
        "        # Validation\n",
        "        valid_loss = 0.0\n",
        "        model.eval()\n",
        "        with torch.no_grad():\n",
        "            for images, labels in valid_loader:\n",
        "                if train_on_gpu:\n",
        "                    images, labels = images.cuda(), labels.cuda()\n",
        "                outputs = model(images)\n",
        "                loss = criterion(outputs, labels)\n",
        "                valid_loss += loss.item() * images.size(0)\n",
        "\n",
        "        # Calculate average losses\n",
        "        train_loss = train_loss / len(train_loader.dataset)\n",
        "        valid_loss = valid_loss / len(valid_loader.dataset)\n",
        "\n",
        "        # Append the losses to the lists\n",
        "        train_losses.append(train_loss)\n",
        "        valid_losses.append(valid_loss)\n",
        "        # Print training and validation losses\n",
        "        print(f'Epoch {epoch+1}/{num_epochs} \\t Training Loss: {train_loss:.4f} \\t Validation Loss: {valid_loss:.4f}')\n",
        "    # Plot the training and validation losses\n",
        "    plt.plot(range(1, num_epochs+1), train_losses, label='Training Loss')\n",
        "    plt.plot(range(1, num_epochs+1), valid_losses, label='Validation Loss')\n",
        "    plt.xlabel(\"Epoch\")\n",
        "    plt.ylabel(\"Loss\")\n",
        "    plt.ylim(0, 1)  # Set y-axis limits\n",
        "    plt.title(\"Training and Validation Losses\")\n",
        "    plt.legend()\n",
        "    plt.show()\n",
        "\n",
        "# Step 5: Validate the Model (Included in Training Function)\n",
        "\n",
        "# Step 6: Test the Model\n",
        "def test_model():\n",
        "    test_loss = 0.0\n",
        "    correct = 0\n",
        "    total = 0\n",
        "    with torch.no_grad():\n",
        "        model.eval()\n",
        "        for images, labels in test_loader:\n",
        "            outputs = model(images)\n",
        "            loss = criterion(outputs, labels)\n",
        "            test_loss += loss.item() * images.size(0)\n",
        "            _, predicted = torch.max(outputs.data, 1)\n",
        "            total += labels.size(0)\n",
        "            correct += (predicted == labels).sum().item()\n",
        "\n",
        "    test_loss = test_loss / len(test_loader.dataset)\n",
        "    accuracy = (correct / total) * 100\n",
        "    print(f'Test Loss: {test_loss:.4f}, Test Accuracy: {accuracy:.2f}%')\n",
        "\n",
        "# Run the training and testing\n",
        "num_epochs = 50\n",
        "valid_losses=train_model(num_epochs)\n",
        "test_model()\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "lMnXtXxamq9d"
      },
      "outputs": [],
      "source": [
        "import copy\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "\n",
        "def newlayer(layer, g):\n",
        "    \"\"\"Clone a layer and pass its parameters through the function g.\"\"\"\n",
        "    layer = copy.deepcopy(layer)\n",
        "    if isinstance(layer, torch.nn.MaxPool2d):\n",
        "      return layer\n",
        "    else:\n",
        "      layer.weight = torch.nn.Parameter(g(layer.weight))\n",
        "      layer.bias = torch.nn.Parameter(g(layer.bias))\n",
        "      return layer"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "CvmGRMeLmq9d"
      },
      "outputs": [],
      "source": [
        "class LRPDropout(nn.Module):\n",
        "    def __init__(self,dropoutrate=0.5):\n",
        "        super(LRPDropout, self).__init__()\n",
        "        self.mask = None\n",
        "        self.rate=dropoutrate\n",
        "\n",
        "    def forward(self, x):\n",
        "        if self.training:\n",
        "            if self.mask is None:\n",
        "              return x\n",
        "            # During training, apply dropout\n",
        "            # print(self.mask.shape,x.shape)\n",
        "            output = (x * self.mask )/ (1 - self.rate)\n",
        "        else:\n",
        "            # During evaluation, don't apply dropout\n",
        "            output = x\n",
        "        return output\n",
        "\n",
        "\n",
        "\n",
        "    def update_mask(self, lrp_values, percentile=50):\n",
        "        percentile=100 - self.rate*100\n",
        "        # calculate the threshold based on LRP values\n",
        "        threshold = np.percentile((torch.abs(lrp_values).cpu().numpy()), percentile)\n",
        "\n",
        "        # create a binary mask based on the threshold\n",
        "        self.mask = (torch.abs(lrp_values) < threshold).float().to(\"cuda\")\n",
        "        # print(self.mask)\n",
        "\n",
        "    def show_mask(self):\n",
        "        print(self.mask)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "jCS5jyIZmq9e"
      },
      "outputs": [],
      "source": [
        "# Step 2: Define the Deep Neural Network Model\n",
        "class DeepNN_LRP(nn.Module):\n",
        "    def __init__(self):\n",
        "        super(DeepNN_LRP, self).__init__()\n",
        "        self.fc1 = nn.Linear(28*28, 512)\n",
        "        self.dropout1= LRPDropout(0.1)\n",
        "        # self.fc2 = nn.Linear(512, 256)\n",
        "        self.fc3 = nn.Linear(512, 128)\n",
        "        self.dropout2= LRPDropout(0.1)\n",
        "        self.fc4 = nn.Linear(128, 64)\n",
        "        self.dropout3= LRPDropout(0.1)\n",
        "        self.fc5 = nn.Linear(64, 10)\n",
        "\n",
        "    def forward(self, x):\n",
        "        x = x.view(-1, 28*28)  # Flatten the images\n",
        "        x = self.dropout1(F.relu(self.fc1(x)))\n",
        "        # x = self.dropout(F.relu(self.fc2(x)))\n",
        "        x = self.dropout2(F.relu(self.fc3(x)))\n",
        "        x = self.dropout3(F.relu(self.fc4(x)))\n",
        "        x = self.fc5(x)\n",
        "        return x\n",
        "\n",
        "# Initialize the network\n",
        "modellrp = DeepNN_LRP()\n",
        "\n",
        "# Step 3: Define the Loss Function and Optimizer\n",
        "criterion = nn.CrossEntropyLoss()\n",
        "optimizer = optim.Adam(modellrp.parameters(), lr=0.001)\n",
        "\n",
        "if train_on_gpu:\n",
        "  modellrp.cuda()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "MKnbqMWcmq9e"
      },
      "outputs": [],
      "source": [
        "def LRP_individual(model, X, target, device):\n",
        "    model.eval()\n",
        "    # Get the list of layers of the network\n",
        "    layers = [module for module in model.modules() if not isinstance(module, torch.nn.Sequential)][1:]\n",
        "    # print(layers)\n",
        "    # Propagate the input\n",
        "    L = len(layers)\n",
        "    A = [X] + [X] * L # Create a list to store the activation produced by each layer\n",
        "    # print(layers)\n",
        "    # print(len(A),layers)\n",
        "    for layer in range(L):\n",
        "        # print(A[layer].shape,layers[layer])\n",
        "        # print(layers[layer])\n",
        "        # if isinstance(layers[layer],torch.nn.Linear):\n",
        "        #   # print(layers[layer])\n",
        "        #   A[layer]=A[layer].reshape(-1,1,layers[layer].in_features)\n",
        "        # print(A[layer].shape,layers[layer])\n",
        "        if isinstance(layers[layer], LRPDropout):\n",
        "          # print(A[layer].shape)\n",
        "          A[layer + 1] =A[layer]\n",
        "        else:\n",
        "          A[layer + 1] = layers[layer].forward(A[layer])\n",
        "\n",
        "    # Get the relevance of the last layer using the highest classification score of the top layer\n",
        "    T = A[-1].to(device)  # Remove .numpy().tolist()\n",
        "    index = target\n",
        "    # print(T.shape)\n",
        "    T = torch.abs(T) * 0\n",
        "    # print(T)\n",
        "    T[-1, index] = 1  # Modify to index the element directly\n",
        "    T = T.to(device)\n",
        "    # Create the list of relevances with (L + 1) elements and assign the value of the last one\n",
        "    R = [None] * L + [(A[-1] * T).data + 1e-6]\n",
        "    # print(\"hi\")\n",
        "     # Propagation procedure from the top-layer towards the lower layers\n",
        "    for layer in range(0, L)[::-1]:\n",
        "\n",
        "        if isinstance(layers[layer], torch.nn.Conv2d) or isinstance(layers[layer], torch.nn.Conv3d) \\\n",
        "                or isinstance(layers[layer],torch.nn.Linear) or isinstance(layers[layer],torch.nn.MaxPool2d) :\n",
        "\n",
        "\n",
        "            rho = lambda p: p\n",
        "\n",
        "            A[layer] = A[layer].data.requires_grad_(True).to(device)\n",
        "\n",
        "            # Step 1: Transform the weights of the layer and executes a forward pass\n",
        "            z = newlayer(layers[layer], rho)\n",
        "\n",
        "            z=z.forward(A[layer]) + 1e-9\n",
        "            # print(layers[layer],z.shape,A[layer].shape)\n",
        "            # print(z.shape,R[layer+1].shape,layers[layer],A[layer].shape)\n",
        "            # Step 2: Element-wise division between the relevance of the next layer and the denominator\n",
        "            # print(R[layer+1].shape, z.shape,layer+1)\n",
        "            s = (R[layer+1] / z).data\n",
        "            # print(s)\n",
        "            # Step 3: Calculate the gradient and multiply it by the activation layer\n",
        "            (z * s).sum().backward()\n",
        "            c = A[layer].grad\n",
        "            R[layer] = (A[layer] * c).cuda().data\n",
        "            # R[layer] = R[layer + 1]\n",
        "            # print(R)\n",
        "\n",
        "        else:\n",
        "            # print(layers[layer],\"else\")\n",
        "            R[layer] = R[layer + 1]\n",
        "        # if layer == 10:\n",
        "        #             # print(\"hi\")\n",
        "        #             R[layer] = R[layer].reshape(-1,512,4,4)\n",
        "    # Return the relevance of the all the layers\n",
        "    model.train()\n",
        "    return R\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "background_save": true,
          "base_uri": "https://localhost:8080/"
        },
        "id": "R7ZBY_Wimq9f",
        "outputId": "67952e7c-4d06-4524-bbc4-ec2a5ee5f97c"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 1/100 \t Training Loss: 0.4442 \t Validation Loss: 0.2387\n",
            "Epoch 2/100 \t Training Loss: 0.2034 \t Validation Loss: 0.1615\n",
            "Epoch 3/100 \t Training Loss: 0.1530 \t Validation Loss: 0.1227\n",
            "Epoch 4/100 \t Training Loss: 0.1227 \t Validation Loss: 0.1213\n",
            "Epoch 5/100 \t Training Loss: 0.1045 \t Validation Loss: 0.1089\n",
            "Epoch 6/100 \t Training Loss: 0.0906 \t Validation Loss: 0.1008\n",
            "Epoch 7/100 \t Training Loss: 0.0882 \t Validation Loss: 0.1244\n",
            "Epoch 8/100 \t Training Loss: 0.0807 \t Validation Loss: 0.1039\n",
            "Epoch 9/100 \t Training Loss: 0.0759 \t Validation Loss: 0.0928\n",
            "Epoch 10/100 \t Training Loss: 0.0684 \t Validation Loss: 0.0994\n",
            "Epoch 11/100 \t Training Loss: 0.0630 \t Validation Loss: 0.0741\n",
            "Epoch 12/100 \t Training Loss: 0.0614 \t Validation Loss: 0.0820\n",
            "Epoch 13/100 \t Training Loss: 0.0604 \t Validation Loss: 0.0822\n",
            "Epoch 14/100 \t Training Loss: 0.0541 \t Validation Loss: 0.0779\n",
            "Epoch 15/100 \t Training Loss: 0.0523 \t Validation Loss: 0.0822\n",
            "Epoch 16/100 \t Training Loss: 0.0511 \t Validation Loss: 0.0807\n",
            "Epoch 17/100 \t Training Loss: 0.0448 \t Validation Loss: 0.0849\n",
            "Epoch 18/100 \t Training Loss: 0.0470 \t Validation Loss: 0.0862\n",
            "Epoch 19/100 \t Training Loss: 0.0395 \t Validation Loss: 0.0825\n",
            "Epoch 20/100 \t Training Loss: 0.0456 \t Validation Loss: 0.0774\n",
            "Epoch 21/100 \t Training Loss: 0.0413 \t Validation Loss: 0.0928\n",
            "Epoch 22/100 \t Training Loss: 0.0357 \t Validation Loss: 0.0818\n",
            "Epoch 23/100 \t Training Loss: 0.0387 \t Validation Loss: 0.0820\n",
            "Epoch 24/100 \t Training Loss: 0.0350 \t Validation Loss: 0.1063\n",
            "Epoch 25/100 \t Training Loss: 0.0383 \t Validation Loss: 0.0953\n",
            "Epoch 26/100 \t Training Loss: 0.0363 \t Validation Loss: 0.0812\n",
            "Epoch 27/100 \t Training Loss: 0.0349 \t Validation Loss: 0.0747\n",
            "Epoch 28/100 \t Training Loss: 0.0332 \t Validation Loss: 0.0842\n",
            "Epoch 29/100 \t Training Loss: 0.0426 \t Validation Loss: 0.0980\n",
            "Epoch 30/100 \t Training Loss: 0.0388 \t Validation Loss: 0.0792\n",
            "Epoch 31/100 \t Training Loss: 0.0396 \t Validation Loss: 0.0789\n",
            "Epoch 32/100 \t Training Loss: 0.0370 \t Validation Loss: 0.0751\n",
            "Epoch 33/100 \t Training Loss: 0.0372 \t Validation Loss: 0.0758\n",
            "Epoch 34/100 \t Training Loss: 0.0369 \t Validation Loss: 0.0858\n",
            "Epoch 35/100 \t Training Loss: 0.0340 \t Validation Loss: 0.0848\n",
            "Epoch 36/100 \t Training Loss: 0.0428 \t Validation Loss: 0.0824\n",
            "Epoch 37/100 \t Training Loss: 0.0388 \t Validation Loss: 0.0850\n",
            "Epoch 38/100 \t Training Loss: 0.0414 \t Validation Loss: 0.0912\n",
            "Epoch 39/100 \t Training Loss: 0.0343 \t Validation Loss: 0.0905\n",
            "Epoch 40/100 \t Training Loss: 0.0335 \t Validation Loss: 0.0846\n",
            "Epoch 41/100 \t Training Loss: 0.0347 \t Validation Loss: 0.0934\n",
            "Epoch 42/100 \t Training Loss: 0.0356 \t Validation Loss: 0.0914\n",
            "Epoch 43/100 \t Training Loss: 0.0363 \t Validation Loss: 0.0901\n",
            "Epoch 44/100 \t Training Loss: 0.0353 \t Validation Loss: 0.0871\n",
            "Epoch 45/100 \t Training Loss: 0.0348 \t Validation Loss: 0.0866\n",
            "Epoch 46/100 \t Training Loss: 0.0321 \t Validation Loss: 0.0911\n",
            "Epoch 47/100 \t Training Loss: 0.0360 \t Validation Loss: 0.0849\n",
            "Epoch 48/100 \t Training Loss: 0.0346 \t Validation Loss: 0.1016\n",
            "Epoch 49/100 \t Training Loss: 0.0353 \t Validation Loss: 0.0950\n",
            "Epoch 50/100 \t Training Loss: 0.0283 \t Validation Loss: 0.0765\n",
            "Epoch 51/100 \t Training Loss: 0.0361 \t Validation Loss: 0.0808\n",
            "Epoch 52/100 \t Training Loss: 0.0328 \t Validation Loss: 0.0851\n",
            "Epoch 53/100 \t Training Loss: 0.0314 \t Validation Loss: 0.0847\n",
            "Epoch 54/100 \t Training Loss: 0.0356 \t Validation Loss: 0.0803\n",
            "Epoch 55/100 \t Training Loss: 0.0320 \t Validation Loss: 0.0912\n",
            "Epoch 56/100 \t Training Loss: 0.0371 \t Validation Loss: 0.0890\n",
            "Epoch 57/100 \t Training Loss: 0.0316 \t Validation Loss: 0.0839\n",
            "Epoch 58/100 \t Training Loss: 0.0334 \t Validation Loss: 0.1124\n",
            "Epoch 59/100 \t Training Loss: 0.0319 \t Validation Loss: 0.1019\n",
            "Epoch 60/100 \t Training Loss: 0.0329 \t Validation Loss: 0.0793\n",
            "Epoch 61/100 \t Training Loss: 0.0286 \t Validation Loss: 0.0921\n",
            "Epoch 62/100 \t Training Loss: 0.0336 \t Validation Loss: 0.0894\n",
            "Epoch 63/100 \t Training Loss: 0.0361 \t Validation Loss: 0.1019\n",
            "Epoch 64/100 \t Training Loss: 0.0346 \t Validation Loss: 0.0966\n",
            "Epoch 65/100 \t Training Loss: 0.0338 \t Validation Loss: 0.0927\n",
            "Epoch 66/100 \t Training Loss: 0.0310 \t Validation Loss: 0.0906\n",
            "Epoch 67/100 \t Training Loss: 0.0310 \t Validation Loss: 0.0920\n",
            "Epoch 68/100 \t Training Loss: 0.0304 \t Validation Loss: 0.0899\n",
            "Epoch 69/100 \t Training Loss: 0.0280 \t Validation Loss: 0.0877\n",
            "Epoch 70/100 \t Training Loss: 0.0330 \t Validation Loss: 0.0925\n",
            "Epoch 71/100 \t Training Loss: 0.0305 \t Validation Loss: 0.0901\n",
            "Epoch 72/100 \t Training Loss: 0.0272 \t Validation Loss: 0.0996\n",
            "Epoch 73/100 \t Training Loss: 0.0310 \t Validation Loss: 0.0917\n",
            "Epoch 74/100 \t Training Loss: 0.0305 \t Validation Loss: 0.0952\n",
            "Epoch 75/100 \t Training Loss: 0.0311 \t Validation Loss: 0.1001\n",
            "Epoch 76/100 \t Training Loss: 0.0316 \t Validation Loss: 0.0952\n",
            "Epoch 77/100 \t Training Loss: 0.0337 \t Validation Loss: 0.0854\n",
            "Epoch 78/100 \t Training Loss: 0.0305 \t Validation Loss: 0.0863\n",
            "Epoch 79/100 \t Training Loss: 0.0270 \t Validation Loss: 0.0951\n",
            "Epoch 80/100 \t Training Loss: 0.0281 \t Validation Loss: 0.0905\n",
            "Epoch 81/100 \t Training Loss: 0.0248 \t Validation Loss: 0.1012\n",
            "Epoch 82/100 \t Training Loss: 0.0295 \t Validation Loss: 0.1023\n",
            "Epoch 83/100 \t Training Loss: 0.0278 \t Validation Loss: 0.0967\n",
            "Epoch 84/100 \t Training Loss: 0.0288 \t Validation Loss: 0.0782\n",
            "Epoch 85/100 \t Training Loss: 0.0256 \t Validation Loss: 0.0945\n",
            "Epoch 86/100 \t Training Loss: 0.0271 \t Validation Loss: 0.0843\n",
            "Epoch 87/100 \t Training Loss: 0.0280 \t Validation Loss: 0.0922\n",
            "Epoch 88/100 \t Training Loss: 0.0271 \t Validation Loss: 0.1216\n",
            "Epoch 89/100 \t Training Loss: 0.0243 \t Validation Loss: 0.0955\n",
            "Epoch 90/100 \t Training Loss: 0.0291 \t Validation Loss: 0.1092\n",
            "Epoch 91/100 \t Training Loss: 0.0291 \t Validation Loss: 0.0802\n",
            "Epoch 92/100 \t Training Loss: 0.0242 \t Validation Loss: 0.0959\n",
            "Epoch 93/100 \t Training Loss: 0.0274 \t Validation Loss: 0.0949\n",
            "Epoch 94/100 \t Training Loss: 0.0303 \t Validation Loss: 0.1129\n",
            "Epoch 95/100 \t Training Loss: 0.0267 \t Validation Loss: 0.1056\n",
            "Epoch 96/100 \t Training Loss: 0.0253 \t Validation Loss: 0.0972\n",
            "Epoch 97/100 \t Training Loss: 0.0246 \t Validation Loss: 0.0973\n",
            "Epoch 98/100 \t Training Loss: 0.0256 \t Validation Loss: 0.1010\n",
            "Epoch 99/100 \t Training Loss: 0.0234 \t Validation Loss: 0.1019\n",
            "Epoch 100/100 \t Training Loss: 0.0239 \t Validation Loss: 0.0982\n"
          ]
        },
        {
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 640x480 with 1 Axes>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        }
      ],
      "source": [
        "\n",
        "# Step 4: Train the Model\n",
        "def train_modellrp(num_epochs,model):\n",
        "    train_losses = []  # List to store training losses\n",
        "    valid_losses = []\n",
        "    for epoch in range(num_epochs):\n",
        "        train_loss = 0.0\n",
        "        model.train()\n",
        "        for images, labels in train_loader:\n",
        "            # print(images.size())\n",
        "            if train_on_gpu:\n",
        "                images, labels = images.cuda(), labels.cuda()\n",
        "            optimizer.zero_grad()\n",
        "            outputs = model(images)\n",
        "            loss = criterion(outputs, labels)\n",
        "            loss.backward()\n",
        "            optimizer.step()\n",
        "            train_loss += loss.item() * images.size(0)\n",
        "            Rel = LRP_individual(modellrp, images.reshape(-1,28*28).float().to(\"cuda\"),labels,device=\"cuda\")\n",
        "            # [print(tensor.shape,end=\"...\") for tensor in Rel]\n",
        "            # print()\n",
        "            avg_tensor=torch.tensor([])\n",
        "            for i in range(len(Rel)):\n",
        "                if(len(avg_tensor)==0):\n",
        "                    avg_tensor=Rel\n",
        "                    for j in range(len(Rel)):\n",
        "                        avg_tensor[j] = torch.mean(Rel[j], dim=0)\n",
        "            avg_tensor[i] = torch.mean(Rel[i], dim=0)\n",
        "            # [print(tensor.shape,end=\"...\") for tensor in avg_tensor]\n",
        "            modellrp.dropout1.update_mask(avg_tensor[1])\n",
        "            modellrp.dropout2.update_mask(avg_tensor[3])\n",
        "            # # print(\"Hi\")\n",
        "            modellrp.dropout3.update_mask(avg_tensor[5])\n",
        "            # Validation\n",
        "        valid_loss = 0.0\n",
        "        model.eval()\n",
        "        with torch.no_grad():\n",
        "            for images, labels in valid_loader:\n",
        "                if train_on_gpu:\n",
        "                    images, labels = images.cuda(), labels.cuda()\n",
        "                outputs = model(images)\n",
        "                loss = criterion(outputs, labels)\n",
        "                valid_loss += loss.item() * images.size(0)\n",
        "\n",
        "        # Calculate average losses\n",
        "        train_loss = train_loss / len(train_loader.dataset)\n",
        "        valid_loss = valid_loss / len(valid_loader.dataset)\n",
        "\n",
        "        # Append the losses to the lists\n",
        "        train_losses.append(train_loss)\n",
        "        valid_losses.append(valid_loss)\n",
        "        # Print training and validation losses\n",
        "        print(f'Epoch {epoch+1}/{num_epochs} \\t Training Loss: {train_loss:.4f} \\t Validation Loss: {valid_loss:.4f}')\n",
        "    # Plot the training and validation losses\n",
        "    plt.plot(range(1, num_epochs+1), train_losses, label='Training Loss')\n",
        "    plt.plot(range(1, num_epochs+1), valid_losses, label='Validation Loss')\n",
        "    plt.xlabel(\"Epoch\")\n",
        "    plt.ylabel(\"Loss\")\n",
        "    plt.ylim(0, 1)  # Set y-axis limits\n",
        "    plt.title(\"Training and Validation Losses\")\n",
        "    plt.legend()\n",
        "    plt.show()\n",
        "\n",
        "\n",
        "# Run the training and testing\n",
        "num_epochs = 100\n",
        "train_modellrp(num_epochs,modellrp)\n",
        "# test_model()\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "LjnBxr54xhFQ",
        "outputId": "1aa137f0-1bbf-4e20-e4c0-5edba76d5e1e"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Test Loss: 0.0944, Test Accuracy: 97.50%\n"
          ]
        }
      ],
      "source": [
        "def test_model(model):\n",
        "    test_loss = 0.0\n",
        "    correct = 0\n",
        "    total = 0\n",
        "    with torch.no_grad():\n",
        "        model.eval()\n",
        "        for images, labels in test_loader:\n",
        "            if train_on_gpu:\n",
        "                images, labels = images.cuda(), labels.cuda()\n",
        "            outputs = model(images)\n",
        "            loss = criterion(outputs, labels)\n",
        "            test_loss += loss.item() * images.size(0)\n",
        "            _, predicted = torch.max(outputs.data, 1)\n",
        "            total += labels.size(0)\n",
        "            correct += (predicted == labels).sum().item()\n",
        "\n",
        "    test_loss = test_loss / len(test_loader.dataset)\n",
        "    accuracy = (correct / total) * 100\n",
        "    print(f'Test Loss: {test_loss:.4f}, Test Accuracy: {accuracy:.2f}%')\n",
        "test_model(modellrp)"
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3 (ipykernel)",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.11.5"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}